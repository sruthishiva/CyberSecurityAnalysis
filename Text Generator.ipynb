{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file='hp.txt'\n",
    "seq_size=32\n",
    "batch_size=16\n",
    "embedding_size=64\n",
    "lstm_size=64\n",
    "gradients_norm=5\n",
    "initial_words=['Hermoine', 'said']\n",
    "predict_top_k=2\n",
    "checkpoint_path='checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(train_file, 'r').read()\n",
    "text = re.sub(r'[^\\w\\s]', '', text).replace(\"\\n\", \"\").replace(\"\\'\", \"\").split() \n",
    "\n",
    "word_counts = Counter(text)\n",
    "sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "n_vocab = len(int_to_vocab)\n",
    "\n",
    "int_text = [vocab_to_int[w] for w in text]\n",
    "num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "out_text = np.zeros_like(in_text)\n",
    "out_text[:-1] = in_text[1:]\n",
    "out_text[-1] = in_text[0]\n",
    "in_text = np.reshape(in_text, (batch_size, -1))\n",
    "out_text = np.reshape(out_text, (batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4832)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "        return logits, state\n",
    "\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "    #words = ['I', 'am']\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "\n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(torch.int64).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 100 Loss: 7.261590480804443\n",
      "Epoch: 1/10 Iteration: 200 Loss: 6.536898612976074\n",
      "Epoch: 1/10 Iteration: 300 Loss: 6.098989486694336\n",
      "Epoch: 2/10 Iteration: 400 Loss: 5.675844192504883\n",
      "Epoch: 3/10 Iteration: 500 Loss: 5.274921894073486\n",
      "Epoch: 3/10 Iteration: 600 Loss: 4.948337078094482\n",
      "Epoch: 4/10 Iteration: 700 Loss: 4.640113353729248\n",
      "Epoch: 5/10 Iteration: 800 Loss: 4.368916988372803\n",
      "Epoch: 5/10 Iteration: 900 Loss: 3.9334826469421387\n",
      "Epoch: 6/10 Iteration: 1000 Loss: 3.9848506450653076\n",
      "Epoch: 7/10 Iteration: 1100 Loss: 3.5826988220214844\n",
      "Epoch: 7/10 Iteration: 1200 Loss: 3.673696517944336\n",
      "Epoch: 8/10 Iteration: 1300 Loss: 3.5829453468322754\n",
      "Epoch: 9/10 Iteration: 1400 Loss: 3.1579761505126953\n",
      "Epoch: 9/10 Iteration: 1500 Loss: 3.2351605892181396\n",
      "Epoch: 10/10 Iteration: 1600 Loss: 3.2852554321289062\n",
      "Epoch: 11/10 Iteration: 1700 Loss: 3.145927667617798\n",
      "Epoch: 11/10 Iteration: 1800 Loss: 2.9105069637298584\n",
      "Epoch: 12/10 Iteration: 1900 Loss: 3.042435884475708\n",
      "Epoch: 13/10 Iteration: 2000 Loss: 2.888298749923706\n",
      "Epoch: 13/10 Iteration: 2100 Loss: 2.506086826324463\n",
      "Epoch: 14/10 Iteration: 2200 Loss: 2.6337599754333496\n",
      "Epoch: 15/10 Iteration: 2300 Loss: 2.732137680053711\n",
      "Epoch: 15/10 Iteration: 2400 Loss: 2.651456356048584\n",
      "Epoch: 16/10 Iteration: 2500 Loss: 2.68754506111145\n",
      "Epoch: 16/10 Iteration: 2600 Loss: 2.7474327087402344\n",
      "Epoch: 17/10 Iteration: 2700 Loss: 2.3003640174865723\n",
      "Epoch: 18/10 Iteration: 2800 Loss: 2.2111024856567383\n",
      "Epoch: 18/10 Iteration: 2900 Loss: 2.304894208908081\n",
      "Epoch: 19/10 Iteration: 3000 Loss: 2.549893856048584\n",
      "Epoch: 20/10 Iteration: 3100 Loss: 2.3676259517669678\n",
      "Epoch: 20/10 Iteration: 3200 Loss: 2.194479465484619\n",
      "Epoch: 21/10 Iteration: 3300 Loss: 2.3575334548950195\n",
      "Epoch: 22/10 Iteration: 3400 Loss: 2.0821428298950195\n",
      "Epoch: 22/10 Iteration: 3500 Loss: 2.165288209915161\n",
      "Epoch: 23/10 Iteration: 3600 Loss: 2.1532504558563232\n",
      "Epoch: 24/10 Iteration: 3700 Loss: 1.802189826965332\n",
      "Epoch: 24/10 Iteration: 3800 Loss: 2.0865542888641357\n",
      "Epoch: 25/10 Iteration: 3900 Loss: 1.8893029689788818\n",
      "Epoch: 26/10 Iteration: 4000 Loss: 1.914548397064209\n",
      "Epoch: 26/10 Iteration: 4100 Loss: 1.8714889287948608\n",
      "Epoch: 27/10 Iteration: 4200 Loss: 1.912730097770691\n",
      "Epoch: 28/10 Iteration: 4300 Loss: 1.976927638053894\n",
      "Epoch: 28/10 Iteration: 4400 Loss: 1.635060429573059\n",
      "Epoch: 29/10 Iteration: 4500 Loss: 1.9559452533721924\n",
      "Epoch: 30/10 Iteration: 4600 Loss: 1.845524787902832\n",
      "Epoch: 30/10 Iteration: 4700 Loss: 2.012603521347046\n",
      "Epoch: 31/10 Iteration: 4800 Loss: 1.8622512817382812\n",
      "Epoch: 32/10 Iteration: 4900 Loss: 1.7884291410446167\n",
      "Epoch: 32/10 Iteration: 5000 Loss: 1.668837547302246\n",
      "Epoch: 33/10 Iteration: 5100 Loss: 1.5374083518981934\n",
      "Epoch: 33/10 Iteration: 5200 Loss: 1.9204188585281372\n",
      "Epoch: 34/10 Iteration: 5300 Loss: 1.6503609418869019\n",
      "Epoch: 35/10 Iteration: 5400 Loss: 1.6432561874389648\n",
      "Epoch: 35/10 Iteration: 5500 Loss: 1.5875324010849\n",
      "Epoch: 36/10 Iteration: 5600 Loss: 1.61360502243042\n",
      "Epoch: 37/10 Iteration: 5700 Loss: 1.7903268337249756\n",
      "Epoch: 37/10 Iteration: 5800 Loss: 1.5602296590805054\n",
      "Epoch: 38/10 Iteration: 5900 Loss: 1.4808728694915771\n",
      "Epoch: 39/10 Iteration: 6000 Loss: 1.4417660236358643\n",
      "Epoch: 39/10 Iteration: 6100 Loss: 1.559585690498352\n",
      "Epoch: 40/10 Iteration: 6200 Loss: 1.4839214086532593\n",
      "Epoch: 41/10 Iteration: 6300 Loss: 1.382486343383789\n",
      "Epoch: 41/10 Iteration: 6400 Loss: 1.4805467128753662\n",
      "Epoch: 42/10 Iteration: 6500 Loss: 1.4631891250610352\n",
      "Epoch: 43/10 Iteration: 6600 Loss: 1.6160281896591187\n",
      "Epoch: 43/10 Iteration: 6700 Loss: 1.7835806608200073\n",
      "Epoch: 44/10 Iteration: 6800 Loss: 1.414523720741272\n",
      "Epoch: 45/10 Iteration: 6900 Loss: 1.6304655075073242\n",
      "Epoch: 45/10 Iteration: 7000 Loss: 1.5727285146713257\n",
      "Epoch: 46/10 Iteration: 7100 Loss: 1.4230560064315796\n",
      "Epoch: 47/10 Iteration: 7200 Loss: 1.5083904266357422\n",
      "Epoch: 47/10 Iteration: 7300 Loss: 1.3534362316131592\n",
      "Epoch: 48/10 Iteration: 7400 Loss: 1.2668014764785767\n",
      "Epoch: 49/10 Iteration: 7500 Loss: 1.466202735900879\n",
      "Epoch: 49/10 Iteration: 7600 Loss: 1.2969179153442383\n"
     ]
    }
   ],
   "source": [
    "net = RNNModule(n_vocab, seq_size, embedding_size, lstm_size)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for e in range(50):\n",
    "    batches = get_batches(in_text, out_text, batch_size, seq_size)\n",
    "    state_h, state_c = net.zero_state(batch_size)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for x, y in batches:\n",
    "        iteration += 1\n",
    "        net.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = torch.tensor(x).to(torch.int64).to(device)\n",
    "        y = torch.tensor(y).to(torch.int64).to(device)\n",
    "\n",
    "        #x = torch.tensor(train).to(torch.int64)\n",
    "\n",
    "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "        loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "\n",
    "        _ = torch.nn.utils.clip_grad_norm_(net.parameters(), gradients_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 1000 == 0:\n",
    "            print('Epoch: {}/{}'.format(e, 50),\n",
    "                  'Iteration: {}'.format(iteration),\n",
    "                  'Loss: {}'.format(loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and looked right person lived for another goblin. inside Harrys school just like a few in there with one wrong voice by the ceiling here facing an cold Voldemort, that now,\" that he was nowhere as he left. \"Dont try and snatching back for so long as horrible as Seeker next. Then hed be in a letter? of great surprise. Harry showed in the silver doors ten wand, as of them looked as if someone had no stamp. moved full came with his hand into sweets. Ron, by Harry looked behind it. All the Fat Lady there was all the way\n"
     ]
    }
   ],
   "source": [
    " predict(device, net, [\"Harry\",\"Potter\"], n_vocab, vocab_to_int, int_to_vocab, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
